{
 "metadata": {
  "kernelspec": {
   "language": "python",
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "version": "3.6.4",
   "file_extension": ".py",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "name": "python",
   "mimetype": "text/x-python"
  },
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 30558,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook",
   "isGpuEnabled": false
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "from datasets import load_dataset, DatasetDict, Dataset\n",
    "from evaluate import load\n",
    "from transformers import AutoTokenizer, DataCollatorForTokenClassification, AutoModelForTokenClassification, TrainingArguments, Trainer"
   ],
   "metadata": {
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "execution": {
     "iopub.status.busy": "2023-09-29T14:48:48.726316Z",
     "iopub.execute_input": "2023-09-29T14:48:48.726563Z",
     "iopub.status.idle": "2023-09-29T14:48:49.04176Z",
     "shell.execute_reply.started": "2023-09-29T14:48:48.726539Z",
     "shell.execute_reply": "2023-09-29T14:48:49.04087Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-07-10T10:13:00.433872Z",
     "start_time": "2024-07-10T10:13:00.399811Z"
    }
   },
   "outputs": [],
   "execution_count": 67
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Fine-Tuning BERT for Named Entity Recognition\n",
    "\n",
    "This notebook covers fine-tuning a pretrained AI-Forever BERT-Reptile model for Named Entity Recognition (NER) on the FactRuEval-2016, CoNLL-2003, Collection3 and BC5CDR datasets. \n",
    "\n",
    "We will use Hugging Face's implementations of BERT and Trainer to fine-tune a model to perform NER. The key steps are:\n",
    "\n",
    "1. Prepare training data and map labels  \n",
    "2. Load pretrained BERT model and tokenizer\n",
    "3. Define training arguments and trainer\n",
    "4. Fine-tune model on training data "
   ],
   "metadata": {}
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-10T10:13:00.456086Z",
     "start_time": "2024-07-10T10:13:00.440125Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_dataset_dict(dataset):\n",
    "    ids, tokens, lengths, ner_tags = [dict() for _ in range(4)]\n",
    "    for key in ['train', 'validation', 'test']:\n",
    "        data = dataset[key]['data'][0]\n",
    "        ids[key], tokens[key], lengths[key], ner_tags[key] = ([] for _ in range(4))\n",
    "        for item in data:\n",
    "            ids[key].append(item[\"id\"])\n",
    "            tokens[key].append(item[\"tokens\"])\n",
    "            lengths[key].append(item[\"length\"])\n",
    "            ner_tags[key].append(item[\"ner_tags\"])\n",
    "\n",
    "    dataset_dict = DatasetDict({\n",
    "        \"train\": Dataset.from_dict({\n",
    "            \"id\": ids[\"train\"],\n",
    "            \"tokens\": tokens[\"train\"],\n",
    "            \"length\": lengths[\"train\"],\n",
    "            \"ner_tags\": ner_tags[\"train\"]\n",
    "        }), \n",
    "        \"validation\": Dataset.from_dict({\n",
    "            \"id\": ids[\"validation\"],\n",
    "            \"tokens\": tokens[\"validation\"],\n",
    "            \"length\": lengths[\"validation\"],\n",
    "            \"ner_tags\": ner_tags[\"validation\"]\n",
    "        }),\n",
    "        \"test\": Dataset.from_dict({\n",
    "            \"id\": ids[\"test\"],\n",
    "            \"tokens\": tokens[\"test\"],\n",
    "            \"length\": lengths[\"test\"],\n",
    "            \"ner_tags\": ner_tags[\"test\"]\n",
    "        })\n",
    "    }) \n",
    "    return dataset_dict"
   ],
   "outputs": [],
   "execution_count": 68
  },
  {
   "cell_type": "code",
   "source": [
    "def get_dataset(dataset_name):\n",
    "    # Load a dataset using the 'datasets' library.\n",
    "    dataset = load_dataset(dataset_name, trust_remote_code=True)\n",
    "    if dataset_name == 'gusevski/factrueval2016':\n",
    "        dataset = get_dataset_dict(dataset)\n",
    "    return dataset\n",
    "    \n"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-09-29T14:48:49.043351Z",
     "iopub.execute_input": "2023-09-29T14:48:49.043979Z",
     "iopub.status.idle": "2023-09-29T14:48:56.560663Z",
     "shell.execute_reply.started": "2023-09-29T14:48:49.043946Z",
     "shell.execute_reply": "2023-09-29T14:48:56.55976Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-07-10T10:13:00.463761Z",
     "start_time": "2024-07-10T10:13:00.457862Z"
    }
   },
   "outputs": [],
   "execution_count": 69
  },
  {
   "cell_type": "code",
   "source": [
    "def get_label_names(dataset):\n",
    "    try:\n",
    "        return dataset['train'].features['ner_tags'].feature.names        \n",
    "    except:\n",
    "        return ['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC']\n",
    "\n"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-09-29T14:48:56.576303Z",
     "iopub.execute_input": "2023-09-29T14:48:56.576711Z",
     "iopub.status.idle": "2023-09-29T14:48:56.611135Z",
     "shell.execute_reply.started": "2023-09-29T14:48:56.576664Z",
     "shell.execute_reply": "2023-09-29T14:48:56.61017Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-07-10T10:13:00.471870Z",
     "start_time": "2024-07-10T10:13:00.465588Z"
    }
   },
   "outputs": [],
   "execution_count": 70
  },
  {
   "cell_type": "code",
   "source": [
    "def align_target(labels, word_ids):\n",
    "    # Define a mapping from beginning (B-) labels to inside (I-) labels\n",
    "    begin2inside = {\n",
    "        1: 2,  # B-LOC -> I-LOC\n",
    "        3: 4,  # B-MISC -> I-MISC\n",
    "        5: 6,  # B-ORG -> I-ORG\n",
    "        7: 8    # B-PER -> I-PER\n",
    "    }\n",
    "\n",
    "    # Initialize an empty list to store aligned labels and a variable to track the last word\n",
    "    align_labels = []\n",
    "    last_word = None\n",
    "\n",
    "    # Iterate through the word_ids\n",
    "    for word in word_ids:\n",
    "        if word is None:\n",
    "            label = -100  # Set label to -100 for None word_ids\n",
    "        elif word != last_word:\n",
    "            label = labels[word]  # Use the label corresponding to the current word_id\n",
    "        else:\n",
    "            label = labels[word]\n",
    "            # Change B- to I- if the previous word is the same\n",
    "            if label in begin2inside:\n",
    "                label = begin2inside[label]  # Map B- to I-\n",
    "\n",
    "        # Append the label to the align_labels list and update last_word\n",
    "        align_labels.append(label)\n",
    "        last_word = word\n",
    "\n",
    "    return align_labels"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-09-29T14:48:59.971656Z",
     "iopub.execute_input": "2023-09-29T14:48:59.9723Z",
     "iopub.status.idle": "2023-09-29T14:48:59.985631Z",
     "shell.execute_reply.started": "2023-09-29T14:48:59.972269Z",
     "shell.execute_reply": "2023-09-29T14:48:59.984714Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-07-10T10:13:00.480914Z",
     "start_time": "2024-07-10T10:13:00.472922Z"
    }
   },
   "outputs": [],
   "execution_count": 71
  },
  {
   "cell_type": "code",
   "source": [
    "def tokenize_fn(batch):\n",
    "    # Tokenize the input batch\n",
    "    tokenized_inputs = tokenizer(batch['tokens'], truncation=True, is_split_into_words=True)\n",
    "\n",
    "    # Extract the labels batch from the input batch\n",
    "    labels_batch = batch['ner_tags']\n",
    "\n",
    "    # Initialize a list to store aligned targets for each example in the batch\n",
    "    aligned_targets_batch = []\n",
    "\n",
    "    # Iterate through each example and align the labels\n",
    "    for i, labels in enumerate(labels_batch):\n",
    "        # Extract the word_ids for the current example\n",
    "        word_ids = tokenized_inputs.word_ids(i)\n",
    "\n",
    "        # Use the align_target function to align the labels\n",
    "        aligned_targets_batch.append(align_target(labels, word_ids))\n",
    "\n",
    "    # Add the aligned labels to the tokenized inputs under the key \"labels\"\n",
    "    tokenized_inputs[\"labels\"] = aligned_targets_batch\n",
    "\n",
    "    # Return the tokenized inputs, including aligned labels\n",
    "    return tokenized_inputs"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-09-29T14:49:00.045727Z",
     "iopub.execute_input": "2023-09-29T14:49:00.046846Z",
     "iopub.status.idle": "2023-09-29T14:49:00.067315Z",
     "shell.execute_reply.started": "2023-09-29T14:49:00.046812Z",
     "shell.execute_reply": "2023-09-29T14:49:00.06591Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-07-10T10:13:00.489403Z",
     "start_time": "2024-07-10T10:13:00.481934Z"
    }
   },
   "outputs": [],
   "execution_count": 72
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-10T10:13:00.500828Z",
     "start_time": "2024-07-10T10:13:00.489403Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Function to compute evaluation metrics from model logits and true labels\n",
    "def compute_metrics(logits, labels, label_names):\n",
    "    metric = load(\"seqeval\")\n",
    "    # Unpack the logits and labels\n",
    "  \n",
    "    # Get predictions from the logits\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "\n",
    "    # Remove ignored index (special tokens)\n",
    "    str_labels = [\n",
    "        [label_names[t] for t in label if t!=-100] for label in labels\n",
    "    ]\n",
    "  \n",
    "    str_preds = [\n",
    "        [label_names[p] for (p, t) in zip(prediction, label) if t != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "\n",
    "    # Compute metrics\n",
    "    results = metric.compute(predictions=str_preds, references=str_labels)\n",
    "  \n",
    "    # Extract key metrics\n",
    "    return results[\"overall_f1\"]"
   ],
   "outputs": [],
   "execution_count": 73
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-10T10:13:03.468593Z",
     "start_time": "2024-07-10T10:13:00.502517Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define the checkpoint you want to use for the tokenizer.\n",
    "checkpoint = \"ai-forever/bert-base-NER-reptile-5-datasets\"\n",
    "\n",
    "# Create a tokenizer instance by loading the pre-trained checkpoint.\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "\n",
    "# Create a DataCollatorForTokenClassification object\n",
    "data_collator = DataCollatorForTokenClassification(tokenizer=tokenizer)"
   ],
   "outputs": [],
   "execution_count": 74
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-10T10:13:03.634035Z",
     "start_time": "2024-07-10T10:13:03.469108Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Configure training arguments using TrainigArguments class\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    # Location to save fine-tuned model \n",
    "    output_dir = f\"fine_tuned_models/{checkpoint}\",\n",
    "\n",
    "    # Evaluate each epoch\n",
    "    eval_strategy = \"epoch\",\n",
    "\n",
    "    # Learning rate for Adam optimizer\n",
    "    learning_rate = 2e-5, \n",
    "  \n",
    "    # Batch sizes for training and evaluation\n",
    "    per_device_train_batch_size = 16,\n",
    "    per_device_eval_batch_size = 16,\n",
    "    \n",
    "    # Number of training epochs\n",
    "    num_train_epochs = 3,\n",
    "\n",
    "    # L2 weight decay regularization\n",
    "    weight_decay = 0.01\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 75
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-10T10:13:03.641188Z",
     "start_time": "2024-07-10T10:13:03.635908Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def train_model(tokenized_dataset, label_names, id2label, label2id):\n",
    "    # Initialize model object with pretrained weights\n",
    "    model = AutoModelForTokenClassification.from_pretrained(\n",
    "        checkpoint,\n",
    "        \n",
    "        # Pass in label mappings\n",
    "        id2label=id2label,  \n",
    "        label2id=label2id\n",
    "    )\n",
    "    \n",
    "    trainer = Trainer(\n",
    "    # Model to train\n",
    "        model=model, \n",
    "      \n",
    "        # Training arguments\n",
    "        args=training_args,\n",
    "    \n",
    "        # Training and validation datasets\n",
    "        train_dataset=tokenized_dataset[\"train\"],\n",
    "        eval_dataset=tokenized_dataset[\"validation\"],\n",
    "    \n",
    "        # Tokenizer\n",
    "        tokenizer=tokenizer,\n",
    "    \n",
    "        # Data collator\n",
    "        data_collator=data_collator \n",
    "    )\n",
    "    trainer.train()\n",
    "    predictions = trainer.predict(tokenized_dataset['test'])\n",
    "    return compute_metrics(predictions.predictions, tokenized_dataset['test']['labels'], label_names)\n",
    "    "
   ],
   "outputs": [],
   "execution_count": 76
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-10T10:13:03.645231Z",
     "start_time": "2024-07-10T10:13:03.642206Z"
    }
   },
   "cell_type": "code",
   "source": [
    "datasets = ['gusevski/factrueval2016',\n",
    "           'RCC-MSU/collection3',\n",
    "           'conll2003',\n",
    "           'ghadeermobasher/BC5CDR-Chemical-Disease']"
   ],
   "outputs": [],
   "execution_count": 77
  },
  {
   "cell_type": "code",
   "source": [
    "print(checkpoint)\n",
    "for dataset_name in datasets:\n",
    "    dataset = get_dataset(dataset_name)\n",
    "    label_names = get_label_names(dataset)\n",
    "    id2label = {k: v for k, v in enumerate(label_names)} \n",
    "    label2id = {v: k for k, v in enumerate(label_names)}\n",
    "    tokenized_dataset = dataset.map(tokenize_fn, batched=True, remove_columns=dataset['train'].column_names)\n",
    "    f1 = train_model(tokenized_dataset, label_names, id2label, label2id)\n",
    "    print(f'Dataset: {dataset_name}, f1: {f1}')"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-09-29T14:55:15.116883Z",
     "iopub.execute_input": "2023-09-29T14:55:15.117568Z",
     "iopub.status.idle": "2023-09-29T14:55:15.694566Z",
     "shell.execute_reply.started": "2023-09-29T14:55:15.11753Z",
     "shell.execute_reply": "2023-09-29T14:55:15.693454Z"
    },
    "trusted": true,
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2024-07-10T10:13:03.645231Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "google-bert/bert-base-multilingual-cased\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Repo card metadata block was not found. Setting CardData to empty.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/7746 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "38f58b64ac574a4195c5d440aa6d8d05"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/2582 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "91a5a4c3e183485f9192492ea5aba618"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/2582 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5c42ecb26fb24155a32232a8fac90b2d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at google-bert/bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\Users\\shipi\\PycharmProjects\\NER-approaches\\venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:439: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at ..\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:455.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1305' max='1455' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1305/1455 16:24 < 01:53, 1.32 it/s, Epoch 2.69/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.044659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.102600</td>\n",
       "      <td>0.032788</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": null
  }
 ]
}
