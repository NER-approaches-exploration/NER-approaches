{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-07-05T11:22:05.166086Z",
     "start_time": "2024-07-05T11:22:03.207385Z"
    }
   },
   "source": [
    "from datasets import load_dataset\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from evaluate import load\n"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-05T11:22:05.169815Z",
     "start_time": "2024-07-05T11:22:05.167295Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# data = datasets.load_dataset(\"DFKI-SLT/cross_ner\", \"conll2003\"\n",
    "def get_data(dataset, config):\n",
    "    return load_dataset(dataset, config)\n",
    "\n"
   ],
   "id": "7e50caf78ddf8c50",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-05T11:22:05.184835Z",
     "start_time": "2024-07-05T11:22:05.170680Z"
    }
   },
   "cell_type": "code",
   "source": [
    "datasets = {\n",
    "    \"universalner/universal_ner\": ['ceb_gja', 'zh_gsd', 'zh_gsdsimp', 'zh_pud', 'hr_set', 'da_ddt', 'en_ewt', 'en_pud', 'de_pud', 'pt_bosque', 'pt_pud', 'ru_pud', 'sr_set', 'sk_snk', 'sv_pud', 'sv_talbanken', 'tl_trg', 'tl_ugnayan'],\n",
    "    \"DFKI-SLT/cross_ner\" : ['ai', 'conll2003', 'literature', 'music', 'politics', 'science']\n",
    "}"
   ],
   "id": "7ae394f7e61761fa",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-05T11:22:05.188645Z",
     "start_time": "2024-07-05T11:22:05.185712Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def label_map(data): # Accessing the label names from the 'ner_tags' feature.\n",
    "    label_names = data['test'].features['ner_tags'].feature.names\n",
    "    # Create mapping from label ID to label string name\n",
    "    get_label = {k: v for k, v in enumerate(label_names)} \n",
    "# Create reverse mapping from label name to label ID\n",
    "    get_id = {v: k for k, v in enumerate(label_names)}\n",
    "    return lambda x : get_label[x], lambda label : get_id[label]\n",
    "\n"
   ],
   "id": "90829d03457906bc",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-05T11:22:05.194479Z",
     "start_time": "2024-07-05T11:22:05.189985Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def recognize_named_entities(dataset):\n",
    "    id2label, label2id = label_map(dataset)\n",
    "    border = int(len(dataset['test']) // 2)\n",
    "    # print(border)\n",
    "    train_df = pd.DataFrame(dataset['test']).iloc[:border] if len(dataset) == 1 else pd.DataFrame(dataset['train'])\n",
    "    test_df = pd.DataFrame(dataset['test']).iloc[border:] if len(dataset) == 1 else pd.DataFrame(dataset['test'])\n",
    "    # validation_df = pd.DataFrame(dataset['validation'])\n",
    "    # train_df = pd.concat([train_df, validation_df], ignore_index=True)\n",
    "    named_entity_dict = {(tok, id2label(prev)): id2label(tag) for _, row in train_df.iterrows() for tok, prev, tag in zip(row['tokens'], [0] + row['ner_tags'][:-1], row['ner_tags']) if tag}\n",
    "    recognized_entities = []\n",
    "    for sentence in test_df['tokens']:\n",
    "        last_tag = 'O'\n",
    "        pred_sentence = []\n",
    "        for word in sentence:\n",
    "            if (word, last_tag) in named_entity_dict:\n",
    "                last_tag = named_entity_dict[(word, last_tag)]\n",
    "                pred_sentence.append(last_tag)\n",
    "            else:\n",
    "                last_tag = 'O'\n",
    "                pred_sentence.append(last_tag)\n",
    "        recognized_entities.append(pred_sentence)\n",
    "    metric = load(\"seqeval\")\n",
    "    res = metric.compute(predictions=recognized_entities, references=[[id2label(tag) for tag in sentence]  for sentence in test_df['ner_tags']])\n",
    "    return res['overall_f1'], res['overall_precision'], res['overall_recall'] "
   ],
   "id": "fd13c708dde9446f",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-05T11:22:17.750466Z",
     "start_time": "2024-07-05T11:22:05.195293Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for dataset, configs in datasets.items():\n",
    "    for cfg in configs:\n",
    "        print(cfg)\n",
    "        data = get_data(dataset, cfg)\n",
    "        print(data['test'].features['ner_tags'].feature.names)\n",
    "        f1, precision, recall = recognize_named_entities(data)\n",
    "        print(f\"precision: {precision}, recall: {recall}, f1: {f1}\\n\")\n",
    "\n",
    "\n"
   ],
   "id": "b6d898f3f563a89a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ceb_gja\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the module from /home/kirill/.cache/huggingface/modules/datasets_modules/datasets/universalner--universal_ner/305d16cdde14f6b2d7922615d92315c452ed9200a563be4a06839d846eb34cdc (last modified on Fri Jul  5 13:18:19 2024) since it couldn't be found locally at universalner/universal_ner, or remotely on the Hugging Face Hub.\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'conllu'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[6], line 4\u001B[0m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m cfg \u001B[38;5;129;01min\u001B[39;00m configs:\n\u001B[1;32m      3\u001B[0m     \u001B[38;5;28mprint\u001B[39m(cfg)\n\u001B[0;32m----> 4\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[43mget_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdataset\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcfg\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      5\u001B[0m     \u001B[38;5;28mprint\u001B[39m(data[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtest\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mfeatures[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mner_tags\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mfeature\u001B[38;5;241m.\u001B[39mnames)\n\u001B[1;32m      6\u001B[0m     f1, precision, recall \u001B[38;5;241m=\u001B[39m recognize_named_entities(data)\n",
      "Cell \u001B[0;32mIn[2], line 3\u001B[0m, in \u001B[0;36mget_data\u001B[0;34m(dataset, config)\u001B[0m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mget_data\u001B[39m(dataset, config):\n\u001B[0;32m----> 3\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mload_dataset\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdataset\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.cache/pypoetry/virtualenvs/bert-JeHI3B9r-py3.11/lib/python3.11/site-packages/datasets/load.py:2594\u001B[0m, in \u001B[0;36mload_dataset\u001B[0;34m(path, name, data_dir, data_files, split, cache_dir, features, download_config, download_mode, verification_mode, ignore_verifications, keep_in_memory, save_infos, revision, token, use_auth_token, task, streaming, num_proc, storage_options, trust_remote_code, **config_kwargs)\u001B[0m\n\u001B[1;32m   2589\u001B[0m verification_mode \u001B[38;5;241m=\u001B[39m VerificationMode(\n\u001B[1;32m   2590\u001B[0m     (verification_mode \u001B[38;5;129;01mor\u001B[39;00m VerificationMode\u001B[38;5;241m.\u001B[39mBASIC_CHECKS) \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m save_infos \u001B[38;5;28;01melse\u001B[39;00m VerificationMode\u001B[38;5;241m.\u001B[39mALL_CHECKS\n\u001B[1;32m   2591\u001B[0m )\n\u001B[1;32m   2593\u001B[0m \u001B[38;5;66;03m# Create a dataset builder\u001B[39;00m\n\u001B[0;32m-> 2594\u001B[0m builder_instance \u001B[38;5;241m=\u001B[39m \u001B[43mload_dataset_builder\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   2595\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpath\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpath\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2596\u001B[0m \u001B[43m    \u001B[49m\u001B[43mname\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2597\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdata_dir\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdata_dir\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2598\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdata_files\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdata_files\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2599\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcache_dir\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcache_dir\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2600\u001B[0m \u001B[43m    \u001B[49m\u001B[43mfeatures\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfeatures\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2601\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdownload_config\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdownload_config\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2602\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdownload_mode\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdownload_mode\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2603\u001B[0m \u001B[43m    \u001B[49m\u001B[43mrevision\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrevision\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2604\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtoken\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtoken\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2605\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstorage_options\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstorage_options\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2606\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtrust_remote_code\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtrust_remote_code\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2607\u001B[0m \u001B[43m    \u001B[49m\u001B[43m_require_default_config_name\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mis\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m   2608\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mconfig_kwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2609\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   2611\u001B[0m \u001B[38;5;66;03m# Return iterable dataset in case of streaming\u001B[39;00m\n\u001B[1;32m   2612\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m streaming:\n",
      "File \u001B[0;32m~/.cache/pypoetry/virtualenvs/bert-JeHI3B9r-py3.11/lib/python3.11/site-packages/datasets/load.py:2301\u001B[0m, in \u001B[0;36mload_dataset_builder\u001B[0;34m(path, name, data_dir, data_files, cache_dir, features, download_config, download_mode, revision, token, use_auth_token, storage_options, trust_remote_code, _require_default_config_name, **config_kwargs)\u001B[0m\n\u001B[1;32m   2298\u001B[0m         error_msg \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124mFor example `data_files=\u001B[39m\u001B[38;5;130;01m{{\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtrain\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m: \u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpath/to/data/train/*.\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mexample_extensions[\u001B[38;5;241m0\u001B[39m]\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m}}\u001B[39;00m\u001B[38;5;124m`\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m   2299\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(error_msg)\n\u001B[0;32m-> 2301\u001B[0m builder_cls \u001B[38;5;241m=\u001B[39m \u001B[43mget_dataset_builder_class\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdataset_module\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdataset_name\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdataset_name\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   2302\u001B[0m \u001B[38;5;66;03m# Instantiate the dataset builder\u001B[39;00m\n\u001B[1;32m   2303\u001B[0m builder_instance: DatasetBuilder \u001B[38;5;241m=\u001B[39m builder_cls(\n\u001B[1;32m   2304\u001B[0m     cache_dir\u001B[38;5;241m=\u001B[39mcache_dir,\n\u001B[1;32m   2305\u001B[0m     dataset_name\u001B[38;5;241m=\u001B[39mdataset_name,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   2315\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mconfig_kwargs,\n\u001B[1;32m   2316\u001B[0m )\n",
      "File \u001B[0;32m~/.cache/pypoetry/virtualenvs/bert-JeHI3B9r-py3.11/lib/python3.11/site-packages/datasets/load.py:252\u001B[0m, in \u001B[0;36mget_dataset_builder_class\u001B[0;34m(dataset_module, dataset_name)\u001B[0m\n\u001B[1;32m    246\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mget_dataset_builder_class\u001B[39m(\n\u001B[1;32m    247\u001B[0m     dataset_module: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mDatasetModule\u001B[39m\u001B[38;5;124m\"\u001B[39m, dataset_name: Optional[\u001B[38;5;28mstr\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    248\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Type[DatasetBuilder]:\n\u001B[1;32m    249\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m lock_importable_file(\n\u001B[1;32m    250\u001B[0m         dataset_module\u001B[38;5;241m.\u001B[39mimportable_file_path\n\u001B[1;32m    251\u001B[0m     ) \u001B[38;5;28;01mif\u001B[39;00m dataset_module\u001B[38;5;241m.\u001B[39mimportable_file_path \u001B[38;5;28;01melse\u001B[39;00m nullcontext():\n\u001B[0;32m--> 252\u001B[0m         builder_cls \u001B[38;5;241m=\u001B[39m \u001B[43mimport_main_class\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdataset_module\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmodule_path\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    253\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m dataset_module\u001B[38;5;241m.\u001B[39mbuilder_configs_parameters\u001B[38;5;241m.\u001B[39mbuilder_configs:\n\u001B[1;32m    254\u001B[0m         dataset_name \u001B[38;5;241m=\u001B[39m dataset_name \u001B[38;5;129;01mor\u001B[39;00m dataset_module\u001B[38;5;241m.\u001B[39mbuilder_kwargs\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdataset_name\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m~/.cache/pypoetry/virtualenvs/bert-JeHI3B9r-py3.11/lib/python3.11/site-packages/datasets/load.py:167\u001B[0m, in \u001B[0;36mimport_main_class\u001B[0;34m(module_path, dataset)\u001B[0m\n\u001B[1;32m    162\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mimport_main_class\u001B[39m(module_path, dataset\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Optional[Union[Type[DatasetBuilder], Type[Metric]]]:\n\u001B[1;32m    163\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Import a module at module_path and return its main class:\u001B[39;00m\n\u001B[1;32m    164\u001B[0m \u001B[38;5;124;03m    - a DatasetBuilder if dataset is True\u001B[39;00m\n\u001B[1;32m    165\u001B[0m \u001B[38;5;124;03m    - a Metric if dataset is False\u001B[39;00m\n\u001B[1;32m    166\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 167\u001B[0m     module \u001B[38;5;241m=\u001B[39m \u001B[43mimportlib\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mimport_module\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodule_path\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    169\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m dataset:\n\u001B[1;32m    170\u001B[0m         main_cls_type \u001B[38;5;241m=\u001B[39m DatasetBuilder\n",
      "File \u001B[0;32m/nix/store/6b1fqdwb3g56j5pazv8zkx9qd0mv3wiz-python3-3.11.9/lib/python3.11/importlib/__init__.py:126\u001B[0m, in \u001B[0;36mimport_module\u001B[0;34m(name, package)\u001B[0m\n\u001B[1;32m    124\u001B[0m             \u001B[38;5;28;01mbreak\u001B[39;00m\n\u001B[1;32m    125\u001B[0m         level \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m--> 126\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_bootstrap\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_gcd_import\u001B[49m\u001B[43m(\u001B[49m\u001B[43mname\u001B[49m\u001B[43m[\u001B[49m\u001B[43mlevel\u001B[49m\u001B[43m:\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpackage\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlevel\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m<frozen importlib._bootstrap>:1204\u001B[0m, in \u001B[0;36m_gcd_import\u001B[0;34m(name, package, level)\u001B[0m\n",
      "File \u001B[0;32m<frozen importlib._bootstrap>:1176\u001B[0m, in \u001B[0;36m_find_and_load\u001B[0;34m(name, import_)\u001B[0m\n",
      "File \u001B[0;32m<frozen importlib._bootstrap>:1147\u001B[0m, in \u001B[0;36m_find_and_load_unlocked\u001B[0;34m(name, import_)\u001B[0m\n",
      "File \u001B[0;32m<frozen importlib._bootstrap>:690\u001B[0m, in \u001B[0;36m_load_unlocked\u001B[0;34m(spec)\u001B[0m\n",
      "File \u001B[0;32m<frozen importlib._bootstrap_external>:940\u001B[0m, in \u001B[0;36mexec_module\u001B[0;34m(self, module)\u001B[0m\n",
      "File \u001B[0;32m<frozen importlib._bootstrap>:241\u001B[0m, in \u001B[0;36m_call_with_frames_removed\u001B[0;34m(f, *args, **kwds)\u001B[0m\n",
      "File \u001B[0;32m~/.cache/huggingface/modules/datasets_modules/datasets/universalner--universal_ner/305d16cdde14f6b2d7922615d92315c452ed9200a563be4a06839d846eb34cdc/universal_ner.py:1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mconllu\u001B[39;00m\n\u001B[1;32m      3\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mdatasets\u001B[39;00m\n\u001B[1;32m      6\u001B[0m _CITATION \u001B[38;5;241m=\u001B[39m \u001B[38;5;124mr\u001B[39m\u001B[38;5;124m\"\"\"\u001B[39m\u001B[38;5;124m\\\u001B[39m\n\u001B[1;32m      7\u001B[0m \u001B[38;5;124m@misc\u001B[39m\u001B[38;5;124m{\u001B[39m\u001B[38;5;124mmayhew2023universal,\u001B[39m\n\u001B[1;32m      8\u001B[0m \u001B[38;5;124m      title=\u001B[39m\u001B[38;5;124m{\u001B[39m\u001B[38;5;124mUniversal NER: A Gold-Standard Multilingual Named Entity Recognition Benchmark}, \u001B[39m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     14\u001B[0m \u001B[38;5;124m}\u001B[39m\n\u001B[1;32m     15\u001B[0m \u001B[38;5;124m\"\"\"\u001B[39m  \u001B[38;5;66;03m# noqa: W605\u001B[39;00m\n",
      "\u001B[0;31mModuleNotFoundError\u001B[0m: No module named 'conllu'"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "5284741c98066c2e",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
