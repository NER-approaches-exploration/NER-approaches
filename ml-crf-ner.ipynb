{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-05T10:12:28.553453600Z",
     "start_time": "2024-07-05T10:12:28.462978900Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\саня\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "from nltk.tag import pos_tag\n",
    "from sklearn_crfsuite import CRF, metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import warnings\n",
    "import pandas as pd\n",
    "from seqeval.metrics import classification_report, f1_score\n",
    "from seqeval.metrics import accuracy_score, precision_score, recall_score\n",
    "import datasets\n",
    "warnings.filterwarnings('ignore')\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-05T10:12:29.480652100Z",
     "start_time": "2024-07-05T10:12:29.470433700Z"
    }
   },
   "outputs": [],
   "source": [
    "def extract_sentences_and_labels(data):\n",
    "    sentences, labels = [], []\n",
    "    for item in data:\n",
    "        words = item['tokens']\n",
    "        tags = item['ner_tags']\n",
    "        sentences.append(words)\n",
    "        labels.append(tags)\n",
    "    return sentences, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "outputs": [],
   "source": [
    "def convert_labels(labels):\n",
    "    label_map = {0: 'O', 1: 'B-MISC', 2: 'I-MISC', 3: 'B-PER', 4: 'I-PER', 5: 'B-ORG', 6: 'I-ORG', 7: 'B-LOC', 8: 'I-LOC'}\n",
    "    return [[label_map[tag] for tag in sent] for sent in labels]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-05T10:12:30.078624500Z",
     "start_time": "2024-07-05T10:12:30.045830800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-05T10:12:35.548770300Z",
     "start_time": "2024-07-05T10:12:30.297770900Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "{'id': '0',\n 'tokens': ['EU',\n  'rejects',\n  'German',\n  'call',\n  'to',\n  'boycott',\n  'British',\n  'lamb',\n  '.'],\n 'pos_tags': [22, 42, 16, 21, 35, 37, 16, 21, 7],\n 'chunk_tags': [11, 21, 11, 12, 21, 22, 11, 12, 0],\n 'ner_tags': [3, 0, 7, 0, 0, 0, 7, 0, 0]}"
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = datasets.load_dataset('conll2003')\n",
    "train_path = data['train']\n",
    "test_path = data['test']\n",
    "val_path = data['validation']\n",
    "train_path[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-05T10:12:39.204563400Z",
     "start_time": "2024-07-05T10:12:35.442674500Z"
    }
   },
   "outputs": [],
   "source": [
    "train_sentences, train_labels = extract_sentences_and_labels(train_path)\n",
    "train_labels = convert_labels(train_labels)\n",
    "\n",
    "test_sentences, test_labels = extract_sentences_and_labels(test_path)\n",
    "test_labels = convert_labels(test_labels)\n",
    "\n",
    "val_sentences, val_labels = extract_sentences_and_labels(val_path)\n",
    "val_labels = convert_labels(val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-05T10:12:39.223326Z",
     "start_time": "2024-07-05T10:12:39.204563400Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "['B-PER', 'O', 'B-LOC', 'O', 'O', 'O', 'B-LOC', 'O', 'O']"
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Extracting features"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-05T10:12:39.263814700Z",
     "start_time": "2024-07-05T10:12:39.223326Z"
    }
   },
   "outputs": [],
   "source": [
    "def sent2feats(sentence):\n",
    "    feats = []\n",
    "    sen_tags = pos_tag(sentence)\n",
    "    for i in range(0, len(sentence)):\n",
    "        word = sentence[i]\n",
    "        word_feats = {'word': word}\n",
    "        if i == 0:\n",
    "            word_feats['prevWord'] = word_feats['prevSecondWord'] = \"<S>\"\n",
    "        elif i == 1:\n",
    "            word_feats['prevWord'] = sentence[0]\n",
    "            word_feats['prevSecondWord'] = '</S>'\n",
    "        else:\n",
    "            word_feats['prevWord'] = sentence[i-1]\n",
    "            word_feats['prevSecondWord'] = sentence[i-2]\n",
    "        if i == len(sentence)-2:\n",
    "            word_feats['nextWord'] = sentence[i+1]\n",
    "            word_feats['nextNextWord'] = '</S>'\n",
    "        elif i==len(sentence)-1:\n",
    "            word_feats['nextWord'] = '</S>'\n",
    "            word_feats['nextNextWord'] = '</S>'\n",
    "        else:\n",
    "            word_feats['nextWord'] = sentence[i+1]\n",
    "            word_feats['nextNextWord'] = sentence[i+2]\n",
    "        word_feats['tag'] = sen_tags[i][1]\n",
    "        if i == 0:\n",
    "            word_feats[\"prevTag\"] = word_feats[\"prevSecondTag\"] = \"<S>\"\n",
    "        elif i == 1:\n",
    "            word_feats[\"prevTag\"] = sen_tags[0][1]\n",
    "            word_feats[\"prevSecondTag\"] = \"</S>\"\n",
    "        else:\n",
    "            word_feats[\"prevTag\"] = sen_tags[i - 1][1]\n",
    "            word_feats[\"prevSecondTag\"] = sen_tags[i - 2][1]\n",
    "        if i == len(sentence) - 2:\n",
    "            word_feats[\"nextTag\"] = sen_tags[i + 1][1]\n",
    "            word_feats[\"nextNextTag\"] = \"</S>\"\n",
    "        elif i == len(sentence) - 1:\n",
    "            word_feats[\"nextTag\"] = \"</S>\"\n",
    "            word_feats[\"nextNextTag\"] = \"</S>\"\n",
    "        else:\n",
    "            word_feats[\"nextTag\"] = sen_tags[i + 1][1]\n",
    "            word_feats[\"nextNextTag\"] = sen_tags[i + 2][1]\n",
    "        feats.append(word_feats)\n",
    "    return feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-05T10:12:39.283143900Z",
     "start_time": "2024-07-05T10:12:39.243500100Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_feats_conll(sentences, labels):\n",
    "    feats = [sent2feats(sentence) for sentence in sentences]\n",
    "    return feats, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-05T10:12:39.283143900Z",
     "start_time": "2024-07-05T10:12:39.246535400Z"
    }
   },
   "outputs": [],
   "source": [
    "def prepare_df(test_data, y_pred):\n",
    "    data = []\n",
    "    for item, pred in zip(test_data, y_pred):\n",
    "        text = item[0]\n",
    "        gt = item[1]\n",
    "        data.append({'text': text, 'ground_truth': gt, 'pred': pred})\n",
    "    df = pd.DataFrame(data)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-05T10:12:39.283143900Z",
     "start_time": "2024-07-05T10:12:39.273441900Z"
    }
   },
   "outputs": [],
   "source": [
    "def print_cm(cm, labels):\n",
    "    print(\"\\n\")\n",
    "    column_width = max([len(x) for x in labels] + [5])  # 5 is value length\n",
    "    empty_cell = \" \" * column_width\n",
    "    print(\"    \" + empty_cell, end=\" \")\n",
    "    for label in labels:\n",
    "        print(\"%{0}s\".format(column_width) % label, end=\" \")\n",
    "    print()\n",
    "    # Print rows\n",
    "    for i, label1 in enumerate(labels):\n",
    "        print(\"    %{0}s\".format(column_width) % label1, end=\" \")\n",
    "        sum = 0\n",
    "        for j in range(len(labels)):\n",
    "            cell = \"%{0}.0f\".format(column_width) % cm[i, j]\n",
    "            sum = sum + int(cell)\n",
    "            print(cell, end=\" \")\n",
    "        print(sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-05T10:12:39.325101300Z",
     "start_time": "2024-07-05T10:12:39.283143900Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_confusion_matrix(y_true,y_pred,labels):\n",
    "    trues, preds = [], []\n",
    "    for yseq_true, yseq_pred in zip(y_true, y_pred):\n",
    "        trues.extend(yseq_true)\n",
    "        preds.extend(yseq_pred)\n",
    "    print_cm(confusion_matrix(trues,preds,labels=labels),labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-05T10:12:39.325101300Z",
     "start_time": "2024-07-05T10:12:39.303340100Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_seq(X_train, Y_train, X_dev, Y_dev, raw_test_data):\n",
    "    crf = CRF(algorithm='lbfgs', c1=0.1, c2=10, max_iterations=50)\n",
    "    crf.fit(X_train, Y_train)\n",
    "    y_pred = crf.predict(X_dev)\n",
    "    print(f\"F1 Score: {f1_score(Y_dev, y_pred)}\")\n",
    "    print(f\"Precision: {precision_score(Y_dev, y_pred)}\")\n",
    "    print(f\"Recall: {recall_score(Y_dev, y_pred)}\")\n",
    "    print(f\"Accuracy: {accuracy_score(Y_dev, y_pred)}\")\n",
    "    print(classification_report(Y_dev, y_pred))\n",
    "    \n",
    "    df = prepare_df(raw_test_data, y_pred)\n",
    "    return crf, df"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Visualize results"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-05T10:13:17.651780500Z",
     "start_time": "2024-07-05T10:12:39.317055700Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.6655570966250578\n",
      "Precision: 0.6965357073737178\n",
      "Recall: 0.6372167138810199\n",
      "Accuracy: 0.9278992139549909\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         LOC       0.61      0.29      0.39       702\n",
      "        MISC       0.77      0.76      0.77      1617\n",
      "         ORG       0.69      0.76      0.72      1668\n",
      "         PER       0.65      0.54      0.59      1661\n",
      "\n",
      "   micro avg       0.70      0.64      0.67      5648\n",
      "   macro avg       0.68      0.59      0.62      5648\n",
      "weighted avg       0.69      0.64      0.65      5648\n",
      "\n",
      "Done with sequence model\n"
     ]
    }
   ],
   "source": [
    "X_train, Y_train = get_feats_conll(train_sentences, train_labels)\n",
    "X_dev, Y_dev = get_feats_conll(test_sentences, test_labels)\n",
    "crf, df = train_seq(X_train, Y_train, X_dev, Y_dev, list(zip(test_sentences, test_labels)))\n",
    "print('Done with sequence model')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
